# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cRgnkKJuYDkfFsTCgF1i__NfiznyvhX2
"""

import streamlit as st
import nltk
import ssl
import requests
import feedparser
from bs4 import BeautifulSoup
from docx import Document
from docx.shared import Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
from datetime import datetime
import time
import random
import os
import io
import urllib.parse
import re

# ConfiguraciÃ³n de pÃ¡gina Streamlit
st.set_page_config(
    page_title="Noticias de Cuba",
    page_icon="ðŸ“°",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Aplicar estilo CSS personalizado
st.markdown("""
    <style>
    .main {
        padding: 2rem;
    }
    .stButton>button {
        width: 100%;
        height: 3rem;
        margin: 1rem 0;
    }
    .noticia {
        padding: 1rem;
        border: 1px solid #ddd;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .fuente-titulo {
        color: #1f77b4;
        font-size: 1.5rem;
        margin: 2rem 0 1rem 0;
    }
    .noticia-titulo {
        color: #2c3e50;
        font-size: 1.2rem;
        margin-bottom: 0.5rem;
    }
    .noticia-meta {
        color: #7f8c8d;
        font-size: 0.9rem;
        margin-bottom: 0.5rem;
    }
    .noticia-resumen {
        color: #34495e;
        font-size: 1rem;
        line-height: 1.5;
    }
    </style>
    """, unsafe_allow_html=True)

# InicializaciÃ³n de NLTK
@st.cache_resource
def inicializar_nltk():
    try:
        _create_unverified_https_context = ssl._create_unverified_context
    except AttributeError:
        pass
    else:
        ssl._create_default_https_context = _create_unverified_https_context

    nltk.download('punkt')
    nltk.download('punkt_tab')
    nltk.download('averaged_perceptron_tagger')

# FunciÃ³n para mostrar el progreso
def mostrar_progreso(texto):
    with st.empty():
        st.write(texto)

# [AquÃ­ van todas las funciones de procesamiento que ya tenÃ­amos]
# separar_palabras(), limpiar_resumen(), generar_resumen_mejorado(), etc.

# Modificamos la funciÃ³n obtener_todas_las_noticias para mostrar progreso
def obtener_todas_las_noticias():
    todas_las_noticias = []

    fuentes = [
        ('OnCuba News', obtener_noticias_oncuba),
        ('Cubadebate', obtener_noticias_cubadebate),
        ('Prensa Latina', obtener_noticias_prensa_latina)
    ]

    progress_bar = st.progress(0)
    status_text = st.empty()

    for i, (nombre_fuente, funcion) in enumerate(fuentes):
        try:
            status_text.text(f"Obteniendo noticias de {nombre_fuente}...")
            noticias_fuente = funcion()

            if noticias_fuente:
                todas_las_noticias.extend(noticias_fuente)
                st.success(f"âœ“ Se obtuvieron {len(noticias_fuente)} noticias de {nombre_fuente}")
            else:
                st.warning(f"No se pudieron obtener noticias de {nombre_fuente}")

            progress_bar.progress((i + 1) / len(fuentes))
            time.sleep(1)

        except Exception as e:
            st.error(f"Error obteniendo noticias de {nombre_fuente}: {str(e)}")
            continue

    progress_bar.empty()
    status_text.empty()

    return todas_las_noticias

# Interfaz principal de Streamlit
def main():
    st.title("ðŸ“° Recopilador de Noticias de Cuba")
    st.markdown("""
    Esta aplicaciÃ³n recopila las Ãºltimas noticias de:
    - OnCuba News
    - Cubadebate
    - Prensa Latina
    """)

    # Sidebar
    with st.sidebar:
        st.header("Opciones")
        auto_download = st.checkbox("Descargar documento automÃ¡ticamente", value=True)
        mostrar_detalles = st.checkbox("Mostrar detalles del proceso", value=False)

    # BotÃ³n principal
    if st.button("ðŸ”„ Obtener Noticias"):
        try:
            with st.spinner('Obteniendo noticias...'):
                noticias = obtener_todas_las_noticias()

                if noticias:
                    # Crear documento Word
                    nombre_archivo = f"Noticias_Cuba_{datetime.now().strftime('%Y%m%d_%H%M')}.docx"

                    # Usar BytesIO para manejar el archivo en memoria
                    docx_buffer = io.BytesIO()
                    crear_documento_word(noticias, docx_buffer)
                    docx_buffer.seek(0)

                    # BotÃ³n de descarga
                    st.download_button(
                        label="ðŸ“¥ Descargar Documento Word",
                        data=docx_buffer,
                        file_name=nombre_archivo,
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                    )

                    # Mostrar resumen
                    st.success(f"Se obtuvieron {len(noticias)} noticias en total")

                    # Mostrar noticias en la web
                    for fuente in ['OnCuba News', 'Cubadebate', 'Prensa Latina']:
                        noticias_fuente = [n for n in noticias if n['fuente'] == fuente]
                        if noticias_fuente:
                            st.markdown(f"### ðŸ“‘ Noticias de {fuente}")
                            for noticia in noticias_fuente:
                                with st.expander(noticia['titulo']):
                                    st.markdown(f"**Fecha:** {noticia['fecha']}")
                                    st.markdown(f"**URL:** [{noticia['url']}]({noticia['url']})")
                                    st.markdown("**Resumen:**")
                                    st.write(noticia['resumen'])

                else:
                    st.error("No se pudieron obtener noticias")

        except Exception as e:
            st.error(f"Error en el proceso: {str(e)}")

if __name__ == "__main__":
    inicializar_nltk()
    main()



